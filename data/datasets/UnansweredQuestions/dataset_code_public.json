{
  "rag_questions": [
    {
      "question_id": "189c8b8a-e59c-4fca-92ad-c02df42cbe40",
      "question": "What activation formats does the fused batched MoE layer return in vLLM?"
    },
    {
      "question_id": "02789461-05fd-435d-9673-91606102d6c9",
      "question": "What are the default values for FP8_MIN and FP8_MAX constants in vLLM's triton_flash_attention module?"
    },
    {
      "question_id": "e852801e-b909-4360-82ea-cedb2a1be919",
      "question": "What determines whether vLLM's sampler returns Pythonized results or deferred Pythonization arguments?"
    },
    {
      "question_id": "0d29b0e8-686c-41b7-9a48-50f8e4bc63de",
      "question": "What's the default value of trust_remote_code in vLLM's LLM class constructor?"
    },
    {
      "question_id": "4235480a-cd9e-42a5-a852-b562386a83a3",
      "question": "What determines the values in cudagraph_inputs_embeds when capturing CUDA graph shapes in vLLM's ModelRunner?"
    },
    {
      "question_id": "6ffdf5f6-fcd3-4d11-8227-8bedd9b33296",
      "question": "What conditions must be met for vLLM's ModelRunner to use CUDA graphs instead of the regular model?"
    },
    {
      "question_id": "c854f979-7900-4772-86c6-f95715529e2d",
      "question": "What is the default timeout value for vLLM RPC operations?"
    },
    {
      "question_id": "48891f49-3fe1-42f9-8bce-4fc4c8027428",
      "question": "What does the Gemma3ForCausalLM constructor assert about the tie_word_embeddings configuration?"
    },
    {
      "question_id": "0d9b0dbb-a25d-47eb-b35b-ce02e23fda2b",
      "question": "What value is passed for ngroups when has_groups is False in the _bmm_chunk_fwd_kernel call?"
    },
    {
      "question_id": "442c5e35-6424-4acf-8e79-f6da53e478b0",
      "question": "What is the default cudagraph_support value for TritonAttentionMetadataBuilder?"
    },
    {
      "question_id": "d39bfccf-9478-4c98-978d-574c596049b2",
      "question": "What does the get_num_new_matched_tokens method in NIXLConnector return?"
    },
    {
      "question_id": "870c92da-36bb-4c17-9bdc-0fdbf401105a",
      "question": "What types are supported as containers in vLLM's JSONTree type definition?"
    },
    {
      "question_id": "925270df-9998-43ab-8603-2ef13c809987",
      "question": "What value does _MAX_IMAGE_SIZE use in vLLM's keye model for determining the image size with most features?"
    },
    {
      "question_id": "6d8a314a-59fa-401c-992b-af647969a6ca",
      "question": "What is the default language value when None is passed to Whisper's validate_language method?"
    },
    {
      "question_id": "87977215-9db5-43a6-9e34-186cdfca86ed",
      "question": "What condition determines whether batch reordering is skipped in GPUModelRunner's update_batch_order method?"
    },
    {
      "question_id": "3be219c4-dec6-4b83-a6e1-39497cf4affd",
      "question": "What are the default values for tensor fields in vLLM's AiterMLAMetadata class?"
    },
    {
      "question_id": "8cb284ad-ec64-4189-ad3a-dd1bcd05bc09",
      "question": "What error is raised when full attention group ids and other attention group ids interleave in HybridKVCacheCoordinator?"
    },
    {
      "question_id": "9ab959ff-efa6-4f66-b2f2-5514f61c82d0",
      "question": "What is the shape and structure of the array returned by the KV cache mapping metadata computation function in TPUModelRunner?"
    },
    {
      "question_id": "f30cdb97-7bbd-469d-8cdf-3b5c50416007",
      "question": "What is the default value of the z parameter in the selective_state_update function call in vLLM's mamba_mixer2.py?"
    },
    {
      "question_id": "c1da62cd-07b5-4f25-8556-c8b33774b4f4",
      "question": "What block size divisibility requirement does HybridKVCacheCoordinator enforce when caching is enabled?"
    },
    {
      "question_id": "706af2a5-9d60-42db-be84-211f217e03f3",
      "question": "What is the default value for min_dynamic_patch parameter in NemotronVL model initialization?"
    },
    {
      "question_id": "4830d85c-33a2-4cef-a1cc-9ccad3e8b51b",
      "question": "What exception is raised when pixel_values has incorrect number of channels in InternS1VisionEmbeddings forward method?"
    },
    {
      "question_id": "937a3e70-2b84-4431-8cb3-08e01991710f",
      "question": "What does the HunyuanA13BReasoningParser return when reasoning_content or response_content has zero length?"
    },
    {
      "question_id": "24caa63b-ddc4-4894-8da4-36d591ede268",
      "question": "What are the input tensor shapes and types used in MiddleAllReduceRMSNormPattern's get_inputs method?"
    },
    {
      "question_id": "c593f6af-5d7c-472c-91f1-39020982d9d4",
      "question": "What are all the registered KV connector names in vLLM's KVConnectorFactory?"
    },
    {
      "question_id": "926b7602-3c5a-48fc-9f25-54eb00d78f0d",
      "question": "What is the default value of the kv_states parameter in HunYuanModel's forward method?"
    },
    {
      "question_id": "794540e4-c04d-4085-9dac-baf3daa46e77",
      "question": "What is the default value for mlp_bias in ExaoneGatedMLP initialization?"
    },
    {
      "question_id": "9495e881-8b94-4f72-8273-93f5b6ddd335",
      "question": "What happens when depths parameter is passed as a string in OvisConfig?"
    },
    {
      "question_id": "56027a35-434a-4c25-9e4d-7964096500c7",
      "question": "What hyperparameters must be shared across all layers in vLLM's FlashInfer backend according to infer_global_hyperparameters?"
    },
    {
      "question_id": "495d3729-74d3-4263-b7e6-89dbdca55574",
      "question": "What is the return type annotation for the _apply_matches function in vLLM's multimodal processing module?"
    },
    {
      "question_id": "9f1db215-19ff-4475-bdd5-dd7caf6bf807",
      "question": "What are the default percentiles calculated for ITL and E2EL metrics in vLLM's serve benchmark?"
    },
    {
      "question_id": "1d220c05-3d71-4af7-95f8-fca998bade77",
      "question": "What happens when min_dynamic_patch is None in InternVL's initialization?"
    },
    {
      "question_id": "fd5cc0f3-ab99-4dcd-8c00-78459828605a",
      "question": "What is the default value of _is_remote_reader in vLLM's shared memory broadcast implementation?"
    },
    {
      "question_id": "a179e20d-14e2-4d73-8cb1-74b1145437e3",
      "question": "What are the default values for alpha and limit parameters in vLLM's SwiGLUOAI activation layer?"
    },
    {
      "question_id": "b6c6a88c-ffc7-486a-a0c7-89ab38cc8e18",
      "question": "What's the default value of the image_mode parameter in vLLM's fetch_video_async method?"
    },
    {
      "question_id": "9d2dd3eb-e569-46ea-a9d5-dea4bb6055e6",
      "question": "What happens if you try to call patch_tensor_parallel_group when the tensor parallel state is already patched?"
    },
    {
      "question_id": "f518d56b-911f-45c8-8392-cfe35cc49704",
      "question": "What does the MessageQueue.create_from_handle method return after calling wait_until_ready in vLLM's shared memory broadcast implementation?"
    },
    {
      "question_id": "2e74c1a5-6081-40e2-9049-a03ef68ee261",
      "question": "What happens when cudagraph_capture_sizes is already set in vLLM's init_with_cudagraph_sizes method?"
    },
    {
      "question_id": "e9157a40-4465-4de7-bd4d-033b4c173493",
      "question": "What is the requires_grad value set for parameters in GPTQMarlin24's process_weights_after_loading method?"
    },
    {
      "question_id": "dc9be3c4-dbfd-4384-8cd1-ce3f37b0ac2e",
      "question": "What happens when encoder_inputs is None in the encoder_seq creation in LLMEngine?"
    },
    {
      "question_id": "b0fa5524-77d7-4288-8967-f606f32d9066",
      "question": "What assertion is made about vocab_size and tp_size when loading fairseq2 LLaMA embedding weights?"
    },
    {
      "question_id": "67336e58-c7ca-4ea4-a6ac-4b976ab3f1e8",
      "question": "What is the default max_threads value used when creating the GrammarCompiler in vLLM's XGrammar backend?"
    },
    {
      "question_id": "e10b9511-a69a-4206-bef4-eaa7f7159090",
      "question": "What does the usage property return in vLLM's KV cache manager?"
    },
    {
      "question_id": "5e9ccc6d-8cc5-4579-b891-8fb40b40012a",
      "question": "What is the default value of the stream parameter in vLLM's OpenAI protocol translation parameters?"
    },
    {
      "question_id": "63554d9e-17e8-478c-b29a-4f3b013c7e91",
      "question": "What is the default value for the multimodal_embeddings parameter in the get_input_embeddings method of the Molmo model?"
    },
    {
      "question_id": "409b78bd-dafb-46b1-b453-3d16a1ae058b",
      "question": "What are the supported bit values for W4A16Sparse24 quantization in vLLM's compressed tensors?"
    },
    {
      "question_id": "d7e4baa5-3106-4de4-b164-4de3211de137",
      "question": "What class does TritonScaledMMLinearKernel inherit from in vLLM's quantization kernels?"
    },
    {
      "question_id": "67acae76-ee3b-46c1-a287-044c71fc78ac",
      "question": "What quantization methods are supported for Mixtral models in vLLM?"
    },
    {
      "question_id": "c544d846-d47c-4254-9ff4-a79467b234ce",
      "question": "How many bytes are allocated for the internal field in ncclUniqueId structure in vLLM's PyNCCL wrapper?"
    },
    {
      "question_id": "16deace0-4e51-4c3d-8f04-ffeadc97a2c3",
      "question": "What is the default value of pp_locks in RayDistributedExecutor?"
    },
    {
      "question_id": "12f7ab0a-fce8-4891-a6ed-9b402171b591",
      "question": "What does the extract_tool_calls method in MistralToolParser return when the bot_token is not present in the model output?"
    },
    {
      "question_id": "96e48e54-5737-4f6e-a274-b5de6c36997d",
      "question": "What happens when key is None in the CPU attention backend's reshape logic?"
    },
    {
      "question_id": "f1fb35e6-1a65-48e1-8c99-f5e25df6f00c",
      "question": "What is the default data type for indices_type parameter in the routing simulator's expert selection method?"
    },
    {
      "question_id": "5dee8def-bbf7-44f4-b163-96968cd1572f",
      "question": "What dimension handling does vLLM's transformers model apply to vision embeddings when they are 2D tensors?"
    },
    {
      "question_id": "4d752f03-1006-4df9-9fde-98b947c79f66",
      "question": "What is the default value of the pin_memory parameter in MultiModalKwargs._try_stack method?"
    },
    {
      "question_id": "b0792edd-53b8-40b5-aaf0-d00416dfae23",
      "question": "What are all possible values for the QuickReduceRegime enum in vLLM's distributed communication?"
    },
    {
      "question_id": "3786b834-ca12-4d88-9b2e-47c2d878827c",
      "question": "What's the default value of max_position_embeddings in ChameleonSwinDecoderLayer?"
    },
    {
      "question_id": "9024881e-e178-462f-8435-7fc4609da96a",
      "question": "What happens when the residual parameter is None in Gemma2DecoderLayer's forward method?"
    },
    {
      "question_id": "a1660e69-44a1-48da-a2a7-5a84be305016",
      "question": "What is the default value of the spec_step_index parameter in DeepSeekMultiTokenPredictor's forward method?"
    },
    {
      "question_id": "22018181-e293-4308-8289-ecfaac26406f",
      "question": "What happens when a reshape operation in vLLM's noop elimination has more than one -1 in the shape parameter?"
    },
    {
      "question_id": "79ef0eef-b8b3-49d1-a8d9-30b99ce0c4d7",
      "question": "What is the default value for the use_bitsandbytes_4bit attribute when it's not present on a parameter object in vLLM's linear layer?"
    },
    {
      "question_id": "92d69198-b21e-416c-a8ba-bc8a6653c4d9",
      "question": "What conditions must be met for use_aiter_and_is_supported to be True in vLLM's FP8 quantization?"
    },
    {
      "question_id": "7d3ccec1-4036-465d-a081-579807af5896",
      "question": "What are the supported spatial pooling modes in LlavaNextVideoPooler?"
    },
    {
      "question_id": "cb7cbccd-ab96-4695-9c7a-9197e6b254a8",
      "question": "What is the default value for apply_router_weight_on_input parameter in the DeepGemm MoE kernel function call?"
    },
    {
      "question_id": "02b4ba56-66f8-4cf5-8d0a-621ea70030e7",
      "question": "What are the compilation levels that cause do_not_compile to be set to True in vLLM's compilation decorator?"
    },
    {
      "question_id": "a96c1a73-d5d0-4599-85ac-9dd74c52c20f",
      "question": "What is the default value of inputs_embeds parameter in DeepSeek model's forward method?"
    },
    {
      "question_id": "94ade925-c345-413f-8410-48cf17c65b99",
      "question": "What prefixes does the AutoWeightsLoader skip in MiniCPM Eagle model when tie_word_embeddings is True?"
    },
    {
      "question_id": "eea9e938-c8f8-4a7a-b262-66e81e9a0201",
      "question": "What are all the NVML GPU instance profile constants defined in vLLM's pynvml module?"
    },
    {
      "question_id": "b9f85113-c988-47ad-993b-01aec1efe22d",
      "question": "What are the shard_id values used in the stacked_params_mapping for gate_up_proj in vLLM's step3_text model?"
    },
    {
      "question_id": "ef591476-8135-4e25-baa9-96c42dbe3ee5",
      "question": "What is the default value of tie_word_embeddings in vLLM's FalconForCausalLM class when the config doesn't specify it?"
    },
    {
      "question_id": "df39833c-7c8c-4e82-b6fd-a66f3b8ce929",
      "question": "What is the default value for engine_id when creating connectors in MultiKVConnector?"
    },
    {
      "question_id": "17204ac3-d7f6-4d82-b2fc-69125f6bb1e9",
      "question": "What datasets are supported by ASRDataset and MLPerfDataset in vLLM benchmarks?"
    },
    {
      "question_id": "d40d1b96-89d9-49b0-b2bb-85202cb491f3",
      "question": "What are some of the test model names used in vLLM's test_utils.py for testing different model types and quantization methods?"
    },
    {
      "question_id": "5ddbbb60-4372-4ce2-b0a9-64e59803e7e1",
      "question": "What is the default value of global_num_experts parameter in the forward_xpu method of vLLM's fused MOE layer?"
    },
    {
      "question_id": "8e79a26d-0035-449d-9fb8-e50ac242396a",
      "question": "What is the default value for the intermediate_tensors parameter in GranitemoehybridForCausalLM's forward method?"
    },
    {
      "question_id": "4ac3026d-7b4f-4723-9116-7aa546efed71",
      "question": "What is the default value of the dst parameter in tensor_model_parallel_gather function?"
    },
    {
      "question_id": "e5baac73-d8dc-4ea5-ac58-41c8d3419f28",
      "question": "What value is used for m_j when the computed maximum is negative infinity in vLLM's Triton attention implementation?"
    },
    {
      "question_id": "b01b004f-6b12-404b-923d-c9e9aac9fb84",
      "question": "What is the default value of the pad_to parameter in vLLM's pad_vocab_size function?"
    },
    {
      "question_id": "6adb31ac-4f50-4dc4-8383-47b6c47a3a3f",
      "question": "What is the default lora_int_id value when lora_request is None in vLLM's sequence?"
    },
    {
      "question_id": "5cd305eb-6726-4663-a730-441d0060daf4",
      "question": "What condition must be met for prompt_tokens_details to be included in the final usage info in vLLM's completion serving?"
    },
    {
      "question_id": "30622359-490d-493a-8f1c-6f05f80bc91b",
      "question": "What happens to input_ids when inputs_embeds is None in LlaVA-NeXT-Video's forward pass?"
    },
    {
      "question_id": "ce1a4fb2-2386-462d-9e53-7c343d769c9a",
      "question": "What environment variable does vLLM's collect_env.py check as a fallback when CUDNN library detection fails?"
    },
    {
      "question_id": "17087e20-d7c9-4c3a-9b8b-0e948a681694",
      "question": "What parameter value is set for requires_grad when creating Parameter objects in _load_weights_from_qkv_linear method?"
    },
    {
      "question_id": "b7a33ae4-5232-47be-b8fc-9370be3ab073",
      "question": "What are the dimensions and data types of the tensors returned by get_inputs method in LastAllReduceRMSNormPattern?"
    },
    {
      "question_id": "3c524f7f-48dd-49f2-95a6-a668f6d5af26",
      "question": "Can draft_probs be None in vLLM's rejection sampler and when does this happen?"
    },
    {
      "question_id": "b18b84c9-0350-4316-bb67-e165ad791ec9",
      "question": "What string prefix is used to identify SSE comments in vLLM's endpoint request processing?"
    },
    {
      "question_id": "a99a010d-4de4-4f17-ac4f-bf31f19db7ea",
      "question": "What parameter type does the copy_operation parameter accept in NixlConnector's set_host_xfer_buffer_ops method?"
    },
    {
      "question_id": "ec9d99ac-0dd1-4e40-b840-df41a82aff1b",
      "question": "What value is used for the num_kv_heads parameter when calling get_mla_metadata in FlashMLAState's graph_capture method?"
    },
    {
      "question_id": "c741046d-939d-4493-bd9a-2a5d89cc5f7f",
      "question": "What is the default value of the bias parameter in the __init__ method of vLLM's mllama model convolution class?"
    },
    {
      "question_id": "df5084f8-4378-43c9-aaf1-55147460923a",
      "question": "What is the constant value for NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_TOTAL in vLLM's pynvml module?"
    },
    {
      "question_id": "83396129-7585-435e-9683-271ddfa46475",
      "question": "What are the expected tensor dimensions for w13_weight_scale in vLLM's MXFP4 quantization layer?"
    },
    {
      "question_id": "da1e13f1-5be1-4854-ac7c-4ee8f6508469",
      "question": "What's the default value of min_stats_update_interval_ms in DPCoordinatorProc's __init__ method?"
    },
    {
      "question_id": "8b219348-ad43-407d-9b13-46cd8fa2fa1c",
      "question": "What does the simple_buffer module return when tokens_recver is None in the KV lookup buffer?"
    },
    {
      "question_id": "f9d7bb96-a32b-4caf-86a0-158a821354c4",
      "question": "What is the default value of the cutlass_block_fp8_supported parameter in apply_w8a8_block_fp8_linear?"
    },
    {
      "question_id": "e9b6052b-222e-432d-9582-064471de4b91",
      "question": "What is the default value of BLOCK_TABLE_EXTENDER in MLACommonMetadataBuilder?"
    },
    {
      "question_id": "4a5b9aca-fbf7-486d-b210-47913db68ba7",
      "question": "What condition prevents tensors from being moved to device in FlashInfer attention backend's prepare method?"
    },
    {
      "question_id": "43927740-4195-49d1-b606-e2e813d3e2fe",
      "question": "What's the default value of the gpu parameter in vLLM's get_max_shared_memory_bytes function?"
    },
    {
      "question_id": "ea812b8d-317d-48bd-a149-bf73747592d5",
      "question": "What is the type hint for the kv_range_for_decode parameter in the _attention_with_mask method?"
    },
    {
      "question_id": "5ff8e342-b4e2-45e1-9ef0-990915c5bb1f",
      "question": "What is the default timeout value for VLLM_RPC_TIMEOUT environment variable?"
    },
    {
      "question_id": "cc784ab6-ef8a-402d-b874-4160ec7c87f1",
      "question": "What determines whether custom allreduce is enabled in vLLM's CudaCommunicator?"
    }
  ]
}